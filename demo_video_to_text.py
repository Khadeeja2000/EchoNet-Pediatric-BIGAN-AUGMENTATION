"""
Demo: Show video and its generated description
"""
import os
import cv2
import pandas as pd
import time


def show_video_and_description(video_path, description, metadata):
    """Show video frames and then display description"""
    cap = cv2.VideoCapture(video_path)
    
    if not cap.isOpened():
        print(f"Error: Could not open video {video_path}")
        return
    
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    print("="*70)
    print("GENAI PROJECT DEMO: Video-to-Text Validation")
    print("="*70)
    print(f"\nðŸ“¹ Video: {os.path.basename(video_path)}")
    print(f"   Resolution: {width}x{height}")
    print(f"   FPS: {fps:.1f}")
    print(f"   Frames: {total_frames}")
    print(f"   Duration: {total_frames/fps:.2f} seconds")
    print("\n" + "="*70)
    print("PLAYING VIDEO...")
    print("="*70)
    print("(Press 'q' to skip to description, or wait for video to finish)\n")
    
    frame_count = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # Resize for display if too large
        display_frame = frame.copy()
        if width > 800 or height > 600:
            scale = min(800/width, 600/height)
            new_w = int(width * scale)
            new_h = int(height * scale)
            display_frame = cv2.resize(frame, (new_w, new_h))
        
        # Add text overlay
        cv2.putText(display_frame, "Video-to-Text Demo", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(display_frame, f"Frame: {frame_count+1}/{total_frames}", 
                   (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        cv2.putText(display_frame, "Press 'q' to see description", 
                   (10, display_frame.shape[0]-20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
        
        cv2.imshow('Video-to-Text Demo - Video Playing', display_frame)
        
        # Check for 'q' key press
        if cv2.waitKey(int(1000/fps)) & 0xFF == ord('q'):
            break
        
        frame_count += 1
    
    cap.release()
    cv2.destroyAllWindows()
    
    # Now show description
    print("\n" + "="*70)
    print("VIDEO ANALYSIS COMPLETE!")
    print("="*70)
    print("\nðŸ“ GENERATED DESCRIPTION:")
    print("-" * 70)
    print(f"   {description}")
    print("-" * 70)
    
    print("\nðŸ“Š EXTRACTED METADATA:")
    print("-" * 70)
    print(f"   View Type: {metadata.get('view', 'N/A')}")
    print(f"   Patient Sex: {metadata.get('sex', 'N/A')}")
    print(f"   Age Bin: {metadata.get('age_bin', 'N/A')}")
    if 'ejection_fraction' in metadata and metadata['ejection_fraction']:
        print(f"   Ejection Fraction: {metadata['ejection_fraction']:.2f}%")
    print("-" * 70)
    
    print("\nâœ… VALIDATION:")
    print("-" * 70)
    print("   Status: Video analyzed successfully")
    print("   Description generated: âœ“")
    print("   Metadata extracted: âœ“")
    print("   Ready for validation comparison")
    print("-" * 70)
    
    print("\n" + "="*70)
    print("DEMO COMPLETE!")
    print("="*70)


def run_demo(num_videos=3):
    """Run demo for multiple videos"""
    df = pd.read_csv('data/processed/manifest.csv')
    if "processed_path" in df.columns:
        df = df[df["processed_path"].astype(str).str.len() > 0].reset_index(drop=True)
    
    # Load existing results if available
    results_file = 'genai_multimodal_results/genai_analysis.json'
    results = []
    if os.path.exists(results_file):
        import json
        with open(results_file, 'r') as f:
            results = json.load(f)
    
    print("\n" + "="*70)
    print("GENAI PROJECT: Video-to-Text Validation Demo")
    print("="*70)
    print(f"\nThis demo will show {min(num_videos, len(df))} videos and their descriptions")
    print("="*70 + "\n")
    
    for i in range(min(num_videos, len(df))):
        row = df.iloc[i]
        video_path = row["processed_path"] if "processed_path" in row else row["file_path"]
        
        if not os.path.exists(video_path):
            print(f"âš  Video {i+1}: {video_path} not found, skipping...\n")
            continue
        
        # Get description from results if available
        if i < len(results):
            description = results[i].get('description', '')
            metadata = results[i].get('metadata', {})
        else:
            # Generate description
            sex = str(row["sex"]).strip().lower()
            age_bin = str(row.get("age_bin", "unknown"))
            view = row.get("view", "unknown")
            sex_str = "Female" if sex.startswith("f") else "Male"
            description = f"Echocardiogram video: {view} view, {sex_str} patient, age {age_bin} years"
            metadata = {
                "view": view,
                "sex": sex_str,
                "age_bin": age_bin,
                "ejection_fraction": row.get("ef", None)
            }
        
        print(f"\n>>> VIDEO {i+1}/{min(num_videos, len(df))} <<<")
        show_video_and_description(video_path, description, metadata)
        
        if i < num_videos - 1:
            print("\n" + "="*70)
            print("Press Enter to continue to next video...")
            print("="*70)
            input()


if __name__ == "__main__":
    import sys
    num_videos = int(sys.argv[1]) if len(sys.argv) > 1 else 1
    run_demo(num_videos)




